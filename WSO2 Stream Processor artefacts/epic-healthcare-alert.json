{
   "templateGroup": {
      "uuid": "epic-healthcare-alert",
      "name": "EPIC Healthcare Alert",
      "description": "Analyze EPIC EMR to Alert Generation",
      "ruleTemplates": [
         {
            "uuid": "analyzing-observation-reports",
            "name": "Analyze Observation Reports",
            "description": "Use EMR data for identifying ABNORMAL results. ",
            "type": "template",
            "instanceCount": "many",
            "script": "var Kafka_Input_Stream = getKafkaInputStreamName('${userInputForKafka_Input_Stream}');\nvar group_id = getTopicGroupId('${userInputForgroup_id}');\nvar threading_option = getThreadingOption('${userInputForthreading_option}');\nvar bootstrap_server = getBootstrapServer('${userInputForbootstrap_server}');\nvar partition_no_list = getPartitionNoList('${userInputForpartition_no_list}');\nvar Report_Type = getReportType('${userInputForReport_Type}');\n\nfunction getKafkaInputStreamName(KafkaInputStream) {\n    return KafkaInputStream;\n}\nfunction getTopicGroupId(groupId) {\n    return groupId;\n}\nfunction getThreadingOption(threadingOption) {\n    return threadingOption;\n}\nfunction getBootstrapServer(bootstrapServer) {\n    return bootstrapServer;\n}\nfunction getPartitionNoList(partitionNoList) {\n    return partitionNoList;\n}\nfunction getReportType(reportType) {\n    return reportType;\n}\n\n",
            "templates": [
               {
                  "type": "siddhiApp",
                  "content": "@App:name(\"Observation Report Siddhi App\")\n@App:description(\"Analyze Observation Reports\")\n\n@info(name = 'Kafka Input Stream') \n@source(\ntype='kafka', \ntopic.list='${Kafka_Input_Stream}', \ngroup.id='${group_id}', \nthreading.option='${threading_option}', \nbootstrap.servers='${bootstrap_server}', \npartition.no.list = '${partition_no_list}',\n@map(type='json' , @attributes(entry=\"$.entry\")))\ndefine stream DiagnosticReportDataStream (entry string);\n\n@info(name='Keeps splited test results') \ndefine stream SplittedDiagnosticReportStream(entry string, jsonElement string);\n\n@info(name='Report_stream') \ndefine stream ReportStream(patientId string ,title string, value double, low double, high double, reportdate string,reportId string,unit string);\n\n@sink(type = 'inMemory' , topic = '${Report_Type}',\n\t@map(type = 'passThrough'))\ndefine stream AlertStream(patientId string , report string, result string,reportdate string,reportId string , highValue string , lowValue string , myValue string );\n\n@info(name = 'split_entry_query')\nfrom DiagnosticReportDataStream#json:tokenize(entry,'$')\nselect *\ninsert into SplittedDiagnosticReportStream;\n\n@info(name='extract_report_fields_query')\nfrom SplittedDiagnosticReportStream\nselect str:split(json:getString(jsonElement,'$.resource.subject.reference'), \"/\" , 8) as patientId , json:getString(jsonElement,'$.resource.code.text') as title , json:getDouble(jsonElement, '$.resource.valueQuantity.value') as value , json:getDouble(jsonElement, '$.resource.referenceRange[0].low.value') as low , json:getDouble(jsonElement, '$.resource.referenceRange[0].high.value') as high,json:getString(jsonElement, '$.resource.effectiveDateTime') as reportdate, json:getString(jsonElement, '$.resource.id') as reportId , json:getString(jsonElement,'$.resource.valueQuantity.unit') as unit\ninsert into ReportStream;\n\n@info(name = 'abnormal_filtering_query')\nfrom ReportStream[value < low or value > high]\nselect patientId as patientId , title as report, 'ABNORMAL' as result , reportdate as reportdate , reportId as reportId , str:concat(high , unit) as highValue , str:concat(low , unit) as lowValue , str:concat(value , unit) as myValue \ninsert into AlertStream;"
               }
            ],
            "properties": {
               "userInputForKafka_Input_Stream": {
                  "fieldName": "Input Kafka Stream ",
                  "description": "Name of the Stream, EPIC EMR Observations carries ",
                  "defaultValue": "glucose-epic"
               },
               "userInputForgroup_id": {
                  "fieldName": "Kafka group Id",
                  "description": "Group Id for the kafka topics",
                  "defaultValue": "test-consumer-group"
               },
               "userInputForthreading_option": {
                  "fieldName": "Threading Options",
                  "description": "This specifies whether the Kafka source is to be run on a single thread, or in multiple threads based on a condition.",
                  "defaultValue": "single.thread"
               },
               "userInputForbootstrap_server": {
                  "fieldName": "Bootstrap Server",
                  "description": "This parameter specifies the list of Kafka servers to which the Kafka sink must publish events. This list should be provided as a set of comma separated values.",
                  "defaultValue": "localhost:9092"
               },
               "userInputForpartition_no_list": {
                  "fieldName": "Partition No List",
                  "description": "The partition number list for the given topic. This is provided as a list of comma-separated values",
                  "defaultValue": "0"
               },
               "userInputForReport_Type": {
                  "fieldName": "In Memory Output  Topic Name",
                  "description": "In memory Topic for publishing, processed alerts to Alert Sending App ",
                  "defaultValue": "DIAGNOSTIC_ALERT"
               }
            }
         },
         {
            "uuid": "sending-abnormal-report-alerts",
            "name": "Sending ABNORMAL Report Alerts",
            "description": "Publish ABNORMALITIES In Reports to Kafka Streams",
            "type": "template",
            "instanceCount": "many",
            "script": "var topic_Name = getTopicName('${userInputFortopic_Name}');\nvar output_kafka_stream = getKafkaOutputStreamName('${userInputForoutput_kafka_stream}');\nvar partition_no = getPartitionNoList('${userInputForpartition_no}');\nvar bootstrap_server = getBootstrapServer('${userInputForbootstrap_server}');\nvar email = getEmail('${userInputForemail}');\n\nfunction getTopicName(InMemoryStreamName) {\n    return InMemoryStreamName;\n}\nfunction getKafkaOutputStreamName(KafkaOutputStream) {\n    return KafkaOutputStream;\n}\nfunction getPartitionNoList(partitionNoList) {\n    return partitionNoList;\n}\nfunction getBootstrapServer(bootstrapServer) {\n    return bootstrapServer;\n}\nfunction getEmail(email) {\n\treturn email;\n}\n\n\n\n\n",
            "templates": [
               {
                  "type": "siddhiApp",
                  "content": "@App:name(\"Observation Alert Siddhi App\")\n@App:description(\"Publish Abnormalities in Observation Reports to Kafka Streams\")\n\n@source(type = 'inMemory' , topic = '${topic_Name}',\n\t@map(type = 'passThrough'))\ndefine stream AlertInputStream(patientId string ,report string, result string,reportdate string,reportId string ,  highValue string , lowValue string , myValue string );\n\n@sink(type = 'kafka',topic = '${output_kafka_stream}', partition.no='${partition_no}',bootstrap.servers='${bootstrap_server}',\n\t@map(type = 'json'))\n@sink(type='log' , prefix=\"Alert : \") \ndefine stream AlertOutputStream(patientId string ,report string, result string, email string,reportdate string,reportId string , highValue string,lowValue string,myValue string);\n\n@info(name = 'send_alert_query')\nfrom AlertInputStream\nselect patientId ,report, result, '${email}' as email , reportdate as reportdate , reportId as reportId  , highValue , lowValue , myValue\ninsert into AlertOutputStream; "
               }
            ],
            "properties": {
               "userInputFortopic_Name": {
                  "fieldName": "In Memory Input Topic Name",
                  "description": "In memory Topic for sourcing processed alerts created by analysing Siddhi app ",
                  "defaultValue": "DIAGNOSTIC_ALERT"
               },
               "userInputForoutput_kafka_stream": {
                  "fieldName": "Output Kafka Stream",
                  "description": "Name of the Stream, EPIC EMR Alerts carries",
                  "defaultValue": "bloodhemoglobin-epic-alert"
               },
               "userInputForpartition_no": {
                  "fieldName": "Partition No List",
                  "description": "The partition number list for the given topic. This is provided as a list of comma-separated values",
                  "defaultValue": "0"
               },
               "userInputForbootstrap_server": {
                  "fieldName": "Bootstrap Server",
                  "description": "This parameter specifies the list of Kafka servers to which the Kafka sink must publish events. This list should be provided as a set of comma separated values.",
                  "defaultValue": "localhost:9092"
               },
               "userInputForemail": {
                  "fieldName": "Email",
                  "description": "Email of the User should be Notified",
                  "defaultValue": "johndoe@test.com"
               }
            }
         },
         {
            "uuid": "analyzing-medication-orders",
            "name": "Analyzing Medication Orders",
            "description": "Use EMR data for identifying Active Medication Orders",
            "type": "template",
            "instanceCount": "many",
            "script": "var Kafka_Input_Stream = getKafkaInputStreamName('${userInputForKafka_Input_Stream}');\nvar group_id = getTopicGroupId('${userInputForgroup_id}');\nvar threading_option = getThreadingOption('${userInputForthreading_option}');\nvar bootstrap_server = getBootstrapServer('${userInputForbootstrap_server}');\nvar partition_no_list = getPartitionNoList('${userInputForpartition_no_list}');\nvar Report_Type = getReportType('${userInputForReport_Type}');\n\nfunction getKafkaInputStreamName(KafkaInputStream) {\n    return KafkaInputStream;\n}\nfunction getTopicGroupId(groupId) {\n    return groupId;\n}\nfunction getThreadingOption(threadingOption) {\n    return threadingOption;\n}\nfunction getBootstrapServer(bootstrapServer) {\n    return bootstrapServer;\n}\nfunction getPartitionNoList(partitionNoList) {\n    return partitionNoList;\n}\nfunction getReportType(reportType) {\n    return reportType;\n}",
            "templates": [
               {
                  "type": "siddhiApp",
                  "content": "@App:name(\"Medication Order Siddhi App\")\n@App:description(\"Analysing Medication Order Reports for Active orders\")\n\n@info(name = 'Kafka Input Stream') \n@source(\ntype='kafka', \ntopic.list='${Kafka_Input_Stream}', \ngroup.id='${group_id}', \nthreading.option='${threading_option}', \nbootstrap.servers='${bootstrap_server}', \npartition.no.list = '${partition_no_list}',\n@map(type='json' , @attributes(entry=\"$.entry\")))\ndefine stream MedicationOrderDataStream (entry string);\n\n@info(name='Keeps splited test results') \ndefine stream SplittedMedicationOrderStream(entry string, jsonElement string);\n\n@info(name='Report_stream') \ndefine stream ReportStream(patientId string, status string,  prescriberId string, Medication string, medicationOrderId string,Dosageinstruction string , frequency int , periodUnits string , period double , startDate string, endDate string );\n\n@sink(type = 'inMemory' , topic = '${Report_Type}',\n\t@map(type = 'passThrough'))\ndefine stream AlertStream(patientId string , prescriberId string , Medication string ,medicationOrderId string, Dosageinstruction string , frequency int, periodUnits string , period double , startDate string , endDate string);\n\n@info(name = 'split_entry_query')\nfrom MedicationOrderDataStream#json:tokenize(entry,'$')\nselect *\ninsert into SplittedMedicationOrderStream;\n\n@info(name='extract_report_fields_query')\nfrom SplittedMedicationOrderStream\nselect str:split(json:getString(jsonElement,'$.resource.patient.reference'), \"/\" , 8) as patientId,json:getString(jsonElement,'$.resource.status') as status, str:split(json:getString(jsonElement,'$.resource.prescriber.reference'), \"/\" , 8) as prescriberId , json:getString(jsonElement, \"$.resource.medicationReference.display\") as Medication, json:getString(jsonElement,'$.resource.id') as medicationOrderId ,json:getString(jsonElement, \"$.resource.dosageInstruction[0].text\") as Dosageinstruction , json:getInt(jsonElement, \"$.resource.dosageInstruction[0].timing.repeat.frequency\") as frequency  , json:getString(jsonElement, \"$.resource.dosageInstruction[0].timing.repeat.periodUnits\") as periodUnits , json:getDouble(jsonElement, \"$.resource.dosageInstruction[0].timing.repeat.period\") as period , str:split(json:getString(jsonElement, \"$.resource.dispenseRequest.validityPeriod.start\") , \"T\" , 0) as startDate, ifThenElse(json:getString(jsonElement, \"$.resource.dispenseRequest.validityPeriod.end\") is null, \"ongoing\", str:split(json:getString(jsonElement, \"$.resource.dispenseRequest.validityPeriod.end\") , \"T\" , 0)) as endDate\ninsert into ReportStream;\n\n@info(name = 'Medication_Order_filtering_query')\nfrom ReportStream[status=='active']\nselect patientId , prescriberId  , Medication ,medicationOrderId , Dosageinstruction , frequency ,periodUnits , period , startDate , endDate\ninsert into AlertStream;"
               }
            ],
            "properties": {
               "userInputForgroup_id": {
                  "fieldName": "Kafka group Id",
                  "description": "Group Id for the kafka topics",
                  "defaultValue": "test-consumer-group"
               },
               "userInputForthreading_option": {
                  "fieldName": "Threading Options",
                  "description": "This specifies whether the Kafka source is to be run on a single thread, or in multiple threads based on a condition.",
                  "defaultValue": "single.thread"
               },
               "userInputForbootstrap_server": {
                  "fieldName": "Bootstrap Server",
                  "description": "This parameter specifies the list of Kafka servers to which the Kafka sink must publish events. This list should be provided as a set of comma separated values.",
                  "defaultValue": "localhost:9092"
               },
               "userInputForpartition_no_list": {
                  "fieldName": "Partition No List",
                  "description": "The partition number list for the given topic. This is provided as a list of comma-separated values",
                  "defaultValue": "0"
               },
               "userInputForReport_Type": {
                  "fieldName": "In Memory Output  Topic Name",
                  "description": "In memory Topic for publishing, processed alerts to Alert Sending App",
                  "defaultValue": "MEDICATION_ALERT"
               },
               "userInputForKafka_Input_Stream": {
                  "fieldName": "Input Kafka Stream",
                  "description": "Name of the Stream, EPIC EMR Medication Order carries",
                  "defaultValue": "Medication-order-epic"
               }
            }
         },
         {
            "uuid": "sending-active-medication-order-alerts",
            "name": "Sending Active Medication Order Alerts",
            "description": "Publishing Active Medication Orders In Reports to Kafka Streams",
            "type": "template",
            "instanceCount": "many",
            "script": "var topic_Name = getTopicName('${userInputFortopic_Name}');\nvar output_kafka_stream = getKafkaOutputStreamName('${userInputForoutput_kafka_stream}');\nvar partition_no = getPartitionNoList('${userInputForpartition_no}');\nvar bootstrap_server = getBootstrapServer('${userInputForbootstrap_server}');\n\nfunction getTopicName(InMemoryStreamName) {\n    return InMemoryStreamName;\n}\nfunction getKafkaOutputStreamName(KafkaOutputStream) {\n    return KafkaOutputStream;\n}\nfunction getPartitionNoList(partitionNoList) {\n    return partitionNoList;\n}\nfunction getBootstrapServer(bootstrapServer) {\n    return bootstrapServer;\n}\nfunction getEmail(email) {\n\treturn email;\n}",
            "templates": [
               {
                  "type": "siddhiApp",
                  "content": "@App:name(\"Medication Order Alert siddhi App\")\n@App:description(\"Publish Active Medication Orders to Kafka Streams\")\n\n@source(type = 'inMemory' , topic = '${topic_Name}',\n\t@map(type = 'passThrough'))\ndefine stream AlertInputStream(patientId string , prescriberId string , Medication string , medicationOrderId string, Dosageinstruction string , frequency int, periodUnits string , period double , startDate string , endDate string);\n\n@sink(type = 'kafka',topic = '${output_kafka_stream}', partition.no='${partition_no}',bootstrap.servers='${bootstrap_server}',\n\t@map(type = 'json'))\n@sink(type='log' , prefix=\"Alert : \") \ndefine stream AlertOutputStream(patientId string , prescriberId string , Medication string ,medicationOrderId string, Dosageinstruction string , frequency int, periodUnits string , period double , startDate string , endDate string);\n\n@info(name = 'send_alert_query')\nfrom AlertInputStream\nselect patientId , prescriberId  , Medication ,medicationOrderId, Dosageinstruction , frequency ,periodUnits , period , startDate , endDate\ninsert into AlertOutputStream; "
               }
            ],
            "properties": {
               "userInputFortopic_Name": {
                  "fieldName": "In Memory Input Topic Name",
                  "description": "In memory Topic for sourcing processed alerts created by analysing Siddhi app",
                  "defaultValue": "MEDICATION_ALERT"
               },
               "userInputForoutput_kafka_stream": {
                  "fieldName": "Output Kafka Stream",
                  "description": "Name of the Stream, EPIC EMR Alerts carries",
                  "defaultValue": "medication-order-epic-alert"
               },
               "userInputForpartition_no": {
                  "fieldName": "Partition No List",
                  "description": "The partition number list for the given topic. This is provided as a list of comma-separated values",
                  "defaultValue": "0"
               },
               "userInputForbootstrap_server": {
                  "fieldName": "Bootstrap Server",
                  "description": "This parameter specifies the list of Kafka servers to which the Kafka sink must publish events. This list should be provided as a set of comma separated values.",
                  "defaultValue": "localhost:9092"
               }
            }
         }
      ]
   }
}